	dataset name	paper	title	notes	paper url	modality	scope	type	data url
0	SAGA22	\cite{cao-etal-2025-enhancing}	Enhancing Talk Moves Analysis in Mathematics Tutoring through Classroom Teaching Discourse	The SAGA22 dataset is based on 148 transcribed videos, it is a dataset of teacher and student talk moves and annotated math tutoring sessions. Talk moves use dialogue acts grounded in Accountable Talk theory.	https://aclanthology.org/2025.coling-main.513/	knowledge	contextual	dynamic	upon request/unknown
1	Reannotated  Spot the Difference and Meetup Datasets	\cite{mohapatra-etal-2024-conversational}	Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units	The Meetup and Spot the Difference datasets were (re-)annotated with Grounding Acts, Common Grounding units, and degrees of grounding.	https://aclanthology.org/2024.lrec-main.352/	knowledge	contextual	dynamic	https://osf.io/qfcnm/?view_only=34e7259fe8fc4ade82d55ba7d5105ffe
2	The Common Ground Corpus	\cite{markowska-etal-2023-finding}	Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations	The Common Ground Corpus is annotated on the top of the LDC CALLHOME American Speech corpus, which consists of collections of 120 unscripted dialogs between close friends or family members. The dialogs are available in both written form and audio. The Common Ground corpus is the first attempt at annotating common ground in a discourse, providing the annotations for beliefs and common ground updates.	https://aclanthology.org/2023.findings-emnlp.551/	knowledge	contextual	dynamic	https://github.com/cogstates/2023-emnlp-common-ground
3	GrounDialog	\cite{zhang-etal-2023-groundialog}	GrounDialog: A Dataset for Repair and Grounding in Task-oriented Spoken Dialogues for Language Learning	An annotated dataset of spoken conversations with repair and grounding patterns. The dataset contains 42 dialogues with 1569 turns.	https://aclanthology.org/2023.bea-1.26/	knowledge	contextual	dynamic	unknown
4	CoomonLayout	\cite{mitsuda-etal-2022-dialogue}	Dialogue Collection for Recording the Process of Building Common Ground in a Collaborative Task	The dataset is built for the CommonLayout task in which two workers lay out the same figure set into a common design through text chat.  To perform the task, they discuss the idea of a final layout and move figures into the same position one by one. The dataset contains 984 dialogues and each dialogue has 28.8 utterances on average.	https://aclanthology.org/2022.lrec-1.618/	knowledge	contextual	dynamic	unknown
5	Reflect	\cite{zhou-etal-2022-reflect}	Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality	Reflect is a dataset that annotates dialogues with explicit common ground (represented as inferences approximating shared knowledge and beliefs) and contains 9k diverse human-generated responses each following one common ground.	https://aclanthology.org/2022.emnlp-main.714/	knowledge	contextual	dynamic	https://inklab.usc.edu/Reflect/
6	SPOLIN	\cite{cho-may-2020-grounding}	Grounding Conversations with Improvised Dialogues	Selected Pairs Of Learnable ImprovisatioN (SPOLIN) corpus is a collection of more than 26K English dialogue turn pairs, each consisting of a prompt and subsequent grounded response, where responses are not only coherent with dialogue context but also initiate the next relevant contribution. 	https://aclanthology.org/2020.acl-main.218/	knowledge	contextual	dynamic	https://justin-cho.com/spolin
7	KNUDGE	\cite{weir-etal-2024-ontologically}	Ontologically Faithful Generation of Non-Player Character Dialogues	KNUDGE (KNowledge Constrained User-NPC Dialogue GEneration) is constructed from side quest dialogues drawn directly from game data of Obsidian Entertainment’s The Outer Worlds, leading to real-world complexities in generation: (1) utterances must remain faithful to the game lore, including character personas and backstories; (2) a dialogue must accurately reveal new quest details to the human player; and (3) dialogues are large trees as opposed to linear chains of utterances. KNUDGE contains 159 dialogue trees.	https://aclanthology.org/2024.emnlp-main.520/	knowledge	contextual	mixed	https://github.com/nweir127/KNUDGE
8	KETOD	\cite{chen-etal-2022-ketod}	KETOD: Knowledge-Enriched Task-Oriented Dialogue	KETOD (Knowledge-Enriched Task-Oriented Dialogue) enriches task-oriented dialogues with chit-chat based on relevant entity knowledge. It contains >5K dialogues.	https://aclanthology.org/2022.findings-naacl.197/	knowledge	contextual	mixed	https://github.com/facebookresearch/ketod
9	ChattyChef	\cite{le-etal-2023-improved}	Improved Instruction Ordering in Recipe-Grounded Conversation	ChattyChef is a dataset of cooking dialogues, designed to support research on instruction-grounded conversational agents. ChattyChef contains 267 dialogues with 26 utterances per dialogue.	https://aclanthology.org/2023.acl-long.561/	knowledge	domain	dynamic	https://github.com/octaviaguo/ChattyChef
10	EHD	\cite{wu-etal-2024-ehdchat}	EHDChat: A Knowledge-Grounded, Empathy-Enhanced Language Model for Healthcare Interactions	Empathetic Healthcare Dialogue (EHD) dataset can help with generating human-like empathetic responses within the healthcare domain. It contains a wide range of synthetic, multi-turn dialogues between doctors and patients that are not only emotionally supportive, but also clinically informative. EHD contains 33K dialogues, with an average of 12 utterances per dialogue.	https://aclanthology.org/2024.sicon-1.10/	knowledge	domain	mixed	https://huggingface.co/datasets/ericw955/EHD
11	MathDial	\cite{macina-etal-2023-mathdial}	MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems	MathDial is a dataset of 3k one-to-one teacher-student tutoring dialogues grounded in multi-step math reasoning problems.	https://aclanthology.org/2023.findings-emnlp.372/	knowledge	domain	mixed	https://github.com/eth-nlped/mathdial
12	ArgSciChat	\cite{ruggeri-etal-2023-dataset}	A Dataset of Argumentative Dialogues on Scientific Papers	ArgSciChat is a dataset of 41 argumentative dialogues between scientists on 20 NLP papers. The dataset includes both exploratory and argumentative questions and answers in a dialogue discourse on a scientific paper.	https://aclanthology.org/2023.acl-long.425/	knowledge	domain	mixed	https://github.com/UKPLab/acl2023-argscichat
13	KdConv	\cite{zhou-etal-2020-kdconv}	KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation	KdConv, a Chinese multi-domain dataset towards multi-turn Knowledge-driven Conversation with 86K utterances and 4.5K dialogues in three domains.	https://aclanthology.org/2020.acl-main.635/	knowledge	domain	mixed	https://github.com/thu-coai/KdConv
14	 List2QA	\cite{sung-etal-2025-structured}	Structured List-Grounded Question Answering	List2QA dataset is designed to evaluate the ability of QA systems to respond effectively using list information. The dataset is created from unlabeled customer service documents with language models and model-based filtering, it has >2K utterances.	https://aclanthology.org/2025.coling-main.558/	knowledge	domain	static	unknown
15	MISeD – Meeting Information Seeking Dialogs dataset	\cite{golany-etal-2024-efficient}	Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts	MISeD – Meeting Information Seeking Dialogs dataset is a dataset of information-seeking dialogues focusing on meeting transcripts for 225 meetings, comprising 432 dialogues, and 4161 query-response pairs.	https://aclanthology.org/2024.findings-emnlp.106/	knowledge	domain	static	https://github.com/google-research-datasets/MISeD
16	Verify-then-Generate	\cite{daheim-etal-2024-stepwise}	Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors	1k student solutions and their stepwise reasoning chains in the domain of multi-step math problem-solving.	https://aclanthology.org/2024.emnlp-main.478/	knowledge	domain	static	https://github.com/eth-lre/verify-then-generate
17	NewsDialogues	\cite{li-etal-2023-newsdialogues}	NewsDialogues: Towards Proactive News Grounded Conversation	A human-to-human Chinese dialogue dataset with 1K conversations with a total of 14.6K utterances and detailed annotations for target topics and knowledge spans.	https://aclanthology.org/2023.findings-acl.224/	knowledge	domain	static	https://github.com/SihengLi99/NewsDialogues
18	CMDQA	\cite{luo-etal-2022-chinese}	Chinese Movie Dialogue Question Answering Dataset	Chinese dialogue-based information-seeking question answering dataset CMDQA, which is mainly applied to the scenario of getting Chinese movie related information. It contains 10K QA dialogs (40K turns in total). 	https://aclanthology.org/2022.rocling-1.2/	knowledge	domain	static	unknown
19	SPORTSINTERVIEW	\cite{sun-etal-2022-sportsinterview}	SPORTSINTERVIEW: A Large-Scale Sports Interview Benchmark for Entity-centric Dialogues	Dataset in the domain of sports interview, it contains two types of external knowledge sources as knowledge grounding, 150K interview sessions and 34K distinct interviewees.	https://aclanthology.org/2022.lrec-1.626/	knowledge	domain	static	unknown/upon request
20	Doc2Bot	\cite{fu-etal-2022-doc2bot}	Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots	Dataset with over 100K turns based on Chinese documents from five domains.	https://aclanthology.org/2022.findings-emnlp.131/	knowledge	domain	static	https://github.com/Doc2Bot/Doc2Bot
21	MultiRefKGC	\cite{zhao-etal-2022-standard}	There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning	A multi-reference Knowledge-Grounded Conversation (KGC) dataset based on conversations from Reddit with 130K dialogues.	https://aclanthology.org/2022.emnlp-main.123/	knowledge	domain	static	https://github.com/TingchenFu/MultiRefKGC
22	CM-CQA	\cite{xia-etal-2022-medconqa}	MedConQA: Medical Conversational Question Answering System based on Knowledge Graphs	A large-scale Chinese Medical CQA (CM-CQA) dataset based on 45 medical subdomains, 33615 entities, 8808 symptoms, 1294753 dialogues.	https://aclanthology.org/2022.emnlp-demos.15/	knowledge	domain	static	https://github.com/WENGSYX/LingYi
23	Social-Dialogues-Coreference	\cite{kruijt-vossen-2022-role}	The Role of Common Ground for Referential Expressions in Social Dialogues	Dataset for resolving third-person references in social dialogues (inner and outer-circle references), based on the episodes of the Friends series. It contains social dialogue and long-term connections between mentions that go beyound a single document.	https://aclanthology.org/2022.crac-1.10/	knowledge	domain	static	https://github.com/cltl/inner-outer-coreference
24	MultiDoc2Dial	\cite{feng-etal-2021-multidoc2dial}	MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents	Conversations grounded in 488 documents, 4796 dialogues in total.	https://aclanthology.org/2021.emnlp-main.498/	knowledge	domain	static	https://doc2dial.github.io/multidoc2dial/
25	TicketTalk	\cite{byrne-etal-2021-tickettalk}	TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems	A movie ticketing dialog dataset with 23,789 annotated conversations that range from completely open-ended and unrestricted to more structured in terms of the knowledge base, discourse features, and number of turns.	https://aclanthology.org/2021.acl-long.55/	knowledge	domain	static	https://git.io/JL8an
26	Doc2Dial	\cite{feng-etal-2020-doc2dial}	doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset	The dataset of goal-oriented dialogues that are grounded in the documents. 4500 annotated conversations grounded in over 450 documents from four domains.	https://aclanthology.org/2020.emnlp-main.652/	knowledge	domain	static	http://doc2dial.github.io/
27	Background-aware movie dataset	\cite{moghe-etal-2018-towards}	Towards Exploiting Background Knowledge for Building Conversation Systems	Background-aware conversation dataset about movies with 90K utterances from 9K conversations grounded in plots, reviewes, comments.	https://aclanthology.org/D18-1255/	knowledge	domain	static	https://github.com/nikitacs16/Holl-E
28	Multi-turn and multi-domain dataset	\cite{eric-etal-2017-key}	Key-Value Retrieval Networks for Task-Oriented Dialogue	The dataset of 3031 dialogues that are grounded through knowledge bases and span three distinct tasks in the in-car personal assistant space: calendar scheduling, weather information retrieval, and point-of-interest navigation.	https://aclanthology.org/W17-5506/	knowledge	domain	static	https://nlp.stanford.edu/blog/a-new-multi-turn-multi-domain-task-oriented-dialogue-dataset
29	SOCCER	\cite{zhang-eickhoff-2021-soccer}	SOCCER: An Information-Sparse Discourse State Tracking Collection in the Sports Commentary Domain	2263 soccer matches including with time-stamped natural language commentary accompanied by discrete events such as a team scoring goals, switching players or being penalized with cards.	https://aclanthology.org/2021.naacl-main.342/	knowledge	mixed	dynamic	https://github.com/bcbi-edu/p_eickhoff_SOCCER
30	FloDial	\cite{raghu-etal-2021-end}	End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs	FloDial has 2738 dialogs grounded on 12 different troubleshooting flowcharts. 	https://aclanthology.org/2021.emnlp-main.357/	knowledge	mixed	dynamic	https://dair-iitd.github.io/FloDial
31	OpenDialKG	\cite{moon-etal-2019-opendialkg}	OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs	Open-ended Dialog and KG parallel corpus called OpenDialKG, where each utterance from 15K human-to-human role-playing dialogs is manually annotated with ground-truth reference to corresponding entities and paths from a large-scale KG with 1M+ facts. 	https://aclanthology.org/P19-1081/	knowledge	mixed	dynamic	https://github.com/facebookresearch/opendialkg
32	FEDI	\cite{petrak-etal-2024-learning}	Learning from Implicit User Feedback, Emotions and Demographic Information in Task-Oriented and Document-Grounded Dialogues	FEDI, the first English task-oriented and document-grounded dialogue dataset annotated with implicit user feedback, emotions and demographic information.	https://aclanthology.org/2024.findings-emnlp.264/	knowledge	mixed	mixed	https://github.com/UKPLab/FEDI
33	Situated Actions in Dialogue	\cite{tam-etal-2023-annotating}	Annotating Situated Actions in Dialogue	Action and Abstract Meaning Representation annotations for first-person point-of-view videos (based on the Fibonacci Weights Task dataset and Epic Kitchens dataset).	https://aclanthology.org/2023.dmr-1.5/	knowledge	mixed	mixed	unknown
34	Japanese Move Recommendations with external and speaker-derived grounding	\cite{kodama-etal-2023-knowledge}	Is a Knowledge-based Response Engaging?: An Analysis on Knowledge-Grounded Dialogue with Information Source Annotation	Annotated knowledge-grounded dialogue corpus Japanese Movie Recommendation Dialogue that contains >5K dialogues. Each entity is annotated with its information source, either derived from external knowledge (database-derived) or the speaker's own knowledge, experiences, and opinions (speaker-derived).	https://aclanthology.org/2023.acl-srw.34/	knowledge	mixed	mixed	unknown
35	Task2Dial	\cite{strathearn-gkatzia-2022-task2dial}	Task2Dial: A Novel Task and Dataset for Commonsense-enhanced Task-based Dialogue Grounded in Documents	A dataset of document-grounded task-based dialogues, where an Information Giver (IG) provides instructions (by consulting a document) to an Information Follower (IF). The dataset contains dialogues with an average 18.15 number of turns grounded in 353 documents.	https://aclanthology.org/2022.dialdoc-1.21/	knowledge	mixed	mixed	http://www.huggingface.co/datasets/cstrathe435/Task2Dial
36	QAConv	\cite{wu-etal-2022-qaconv}	QAConv: Question Answering on Informative Conversations	A question-answering (QA) dataset that uses conversations as a knowledge source and offers 34608 QA pairs with both human-written and machine-generated questions.	https://aclanthology.org/2022.acl-long.370/	knowledge	mixed	mixed	https://github.com/salesforce/QAConv
37	A Dataset for Conversational Curiosity	\cite{rodriguez-etal-2020-information}	Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity	14K dialogues (181K utterances) where users and assistants converse about geographic topics like geopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, message-level dialog acts, grounding to Wikipedia, and user reactions to messages.	https://aclanthology.org/2020.emnlp-main.655/	knowledge	mixed	mixed	http://curiosity.pedro.ai/
38	BridgeKG	\cite{schneider-etal-2024-bridging}	Bridging Information Gaps in Dialogues with Grounded Exchanges Using Knowledge Graphs	Annotated human conversations across five knowledge domains, 26 information-seeking conversations and 669 dialogue turns.	https://aclanthology.org/2024.sigdial-1.10/	knowledge	mixed	static	https://github.com/philotron/Bridge-KG
39	DialogStudio	\cite{zhang-etal-2024-dialogstudio}	DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI	Collection with diverse data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues.	https://aclanthology.org/2024.findings-eacl.152/	knowledge	mixed	static	https://github.com/salesforce/DialogStudio
40	SK-TOD	\cite{zhao-etal-2023-others}	What do others think?: Task-Oriented Conversational Modeling with Subjective Knowledge	Subjective-Knowledge Task-Oriented Dialogue (SK-TOD) dataset contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. SK-TOD has >9K instances consisting of subjective user requests and subjective knowledge-grounded responses.	https://aclanthology.org/2023.sigdial-1.28/	knowledge	mixed	static	https://github.com/alexa/dstc11-track5
41	HPD	\cite{chen-etal-2023-large}	Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters	Harry Potter Dialogue (HPD) dataset in English and Chinese is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. It has >1K dialogues.	https://aclanthology.org/2023.findings-emnlp.570/	knowledge	mixed	static	https://nuochenpku.github.io/HPD.github.io
42	RSD	\cite{hedayatnia-etal-2022-systematic}	A Systematic Evaluation of Response Selection for Open Domain Dialogue	Response Selection Data (RSD) dataset where responses from multiple response generators produced for the same dialog context are manually annotated as appropriate (positive) and inappropriate (negative). The data has 100K interactiona and 2.5 million turns.	https://aclanthology.org/2022.sigdial-1.30/	knowledge	mixed	static	unknown
43	COMET	\cite{kottur-etal-2022-navigating}	Navigating Connected Memories with a Task-oriented Dialog System	A new task-oriented dialog dataset COMET, which contains 11.5k user-assistant dialogs (totalling 103k utterances), grounded in simulated personal memory graphs.	https://aclanthology.org/2022.emnlp-main.160/	knowledge	mixed	static	https://github.com/facebookresearch/comet_memory_dialog
44	Augmented MultiWOZ 2.1	\cite{kim-etal-2020-beyond}	Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access	An augmented version of MultiWOZ 2.1, which includes new out-of-API-coverage turns and responses grounded on external knowledge sources. The dataset contains >10K dialogues with >9K augmented turns.	https://aclanthology.org/2020.sigdial-1.35/	knowledge	mixed	static	unknown
45	MGConvRex	\cite{xu-etal-2020-user}	User Memory Reasoning for Conversational Recommendation	A new Memory Graph (MG) - Conversational Recommendation parallel corpus called MGConvRex with 7K+ human-to-human role-playing dialogs, grounded on a large-scale user memory bootstrapped from real-world user scenarios.	https://aclanthology.org/2020.coling-main.463/	knowledge	mixed	static	upon request/unknown
46	Annotated Weights Task Dataset	\cite{khebour-etal-2024-common}	Common Ground Tracking in Multimodal Dialogue	A dataset of multimodal interactions in a shared physical space with speech transcriptions, prosodic features, gestures, actions, and facets of collaboration (based on the Weights Task).	https://aclanthology.org/2024.lrec-main.318/	multimodal	contextual	dynamic	https://github.com/csu-signal/Common-Ground-detection
47	J-CRe3	\cite{ueda-etal-2024-j}	J-CRe3: A Japanese Conversation Dataset for Real-world Reference Resolution	A Japanese Conversation dataset for Real-world Reference Resolution (J-CRe3) that contains video and dialogue audio of real-world conversations between two people acting as a master and an assistant robot at home. The dataset is annotated with crossmodal tags between phrases in the utterances and the object bounding boxes in the video frames. These tags include indirect reference relations, such as predicate-argument structures and bridging references as well as direct reference relations. 	https://aclanthology.org/2024.lrec-main.829/	multimodal	contextual	dynamic	https://github.com/riken-grp/J-CRe3
48	LoCoMo	\cite{maharana-etal-2024-evaluating}	Evaluating Very Long-Term Conversational Memory of LLM Agents	LoCoMo, a dataset of very long-term conversations, each encompassing 600 turns and 16K tokens on avg., over up to 32 sessions. The dialogues are grounded on personas and temporal event graphs.	https://aclanthology.org/2024.acl-long.747/	multimodal	contextual	dynamic	https://snap-research.github.io/locomo
49	Chinese Whispers	\cite{kontogiorgos-etal-2020-chinese}	Chinese Whispers: A Multimodal Dataset for Embodied Language Grounding	The corpus with 34 interactions, where each subject first assembles and then instructs how to assemble IKEA furniture. The dataset has speech, eye-gaze, pointing gestures, and object movements, as well as subjective interpretations of mutual understanding, collaboration and task recall.	https://aclanthology.org/2020.lrec-1.93/	multimodal	contextual	dynamic	https://www.kth.se/profile/diko/page/material
50	Spatial AMR and Grounded Minecraft Dataset	\cite{bonn-etal-2020-spatial}	Spatial AMR: Expanded Spatial Annotation in the Context of a Grounded Minecraft Corpus	A multimodal corpus consisting of 170 3D structure-building dialogues between a human architect and human builder in Minecraft. The data contain sentence-level and document-level annotations designed to capture implicit information, the coordinates and the spatial framework annotation ground the spatial language in the dialogues.	https://aclanthology.org/2020.lrec-1.601/	multimodal	contextual	dynamic	https://github.com/cu-clear/Spatial-AMR/
51	OneCommon	\cite{udagawa-etal-2020-linguistic}	A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial Expressions	OneCommon Corpus for visual conversational grounding with 600 dialogues annotated with spatial expressions that capture predicate-argument structure, modification and ellipsis.	https://aclanthology.org/2020.findings-emnlp.67/	multimodal	contextual	dynamic	https://github.com/Alab-NII/onecommon
52	The Niki and Julie Corpus	\cite{artsteinNikiJulieCorpus2018}	The Niki and Julie Corpus: Collaborative Multimodal Dialogues between Humans, Robots, and Virtual Agents	The Niki and Julie corpus contains more than 600 dialogues between human participants and a human-controlled robot or virtual agent, engaged in a series of collaborative item-ranking tasks designed to measure influence. Some of the dialogues contain deliberate conversational errors by the robot, designed to simulate the kinds of conversational breakdown that are typical of present-day automated agents. Data collected include audio and video recordings, the results of the ranking tasks, and questionnaire responses; some of the recordings have been transcribed and annotated for verbal and nonverbal feedback. 	https://aclanthology.org/L18-1463/	multimodal	contextual	dynamic	upon request/unknown
53	REX Corpora	\cite{takenobuREXCorporaCollection2012}	The REX corpora: A collection of multimodal corpora of referring expressions in collaborative problem solving dialogues	A collection of multimodal corpora of referring expressions, the REX corpora. The corpora include time-aligned extra-linguistic information such as participant actions and eye-gaze on top of linguistic information, also the dialogues were collected with various configurations in terms of the puzzle type, hinting and language. The REX corpora contain 226 dialogues.	http://www.lrec-conf.org/proceedings/lrec2012/pdf/676_Paper.pdf	multimodal	contextual	dynamic	upon request/unknown
54	GreThE	\cite{moutti-etal-2022-dataset}	A Dataset for Speech Emotion Recognition in Greek Theatrical Plays	GreThE, the Greek Theatrical Emotion dataset, a publicly available data collection for speech emotion recognition in Greek theatrical plays. The dataset contains 500 utterances that have been annotated in terms of their emotional content (valence and arousal).	https://aclanthology.org/2022.lrec-1.111/	multimodal	contextual	mixed	https://github.com/magcil/GreThE
55	Memory Dialog	\cite{moon-etal-2019-memory-grounded}	Memory Grounded Conversational Reasoning	A corpus of memory grounded conversations, which comprises human-to-human role-playing dialogues given synthetic memory graphs with simulated attributes and connections to real entities (e.g. locations, events, public entities).	https://aclanthology.org/D19-3025/	multimodal	contextual	mixed	unknown
56	FUSE	\cite{titung-alm-2024-fuse}	FUSE - FrUstration and Surprise Expressions: A Subtle Emotional Multimodal Language Corpus	FrUstration and Surprise Expressions (FUSE) is a multimodal corpus for expressive task-based spoken language and dialogue, focusing on language use under frustration and surprise. 	https://aclanthology.org/2024.lrec-main.666/	multimodal	contextual	static	https://fusecorpus.github.io/FUSE/
57	MPCHAT	\cite{ahn-etal-2023-mpchat}	MPCHAT: Towards Multimodal Persona-Grounded Conversation	MPCHAT is the first multimodal persona-based dialogue dataset which extends persona with both text and images to contain episodic memories. It contains 15K dialogues sourced from Reddit.	https://aclanthology.org/2023.acl-long.189/	multimodal	contextual	static	https://github.com/ahnjaewoo/MPCHAT
58	NICE	\cite{chen-etal-2021-nice-neural}	NICE: Neural Image Commenting with Empathy	Neural Image Commenting with Empathy (NICE) dataset consists of almost two million images and the corresponding human-generated comments with a set of human annotations. The dataset can be used to generate dialogues grounded in a user-shared image with increased emotion and empathy while minimizing offensive outputs.	https://aclanthology.org/2021.findings-emnlp.380/	multimodal	contextual	static	https://nicedataset.github.io/
59	SIMMC 2.0	\cite{kottur-etal-2021-simmc}	SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal Conversations	A dataset for Situated and Interactive Multimodal Conversations, SIMMC 2.0, which includes 11K task-oriented user-assistant dialogs (117K utterances) in the shopping domain, grounded in immersive and photo-realistic scenes.	https://aclanthology.org/2021.emnlp-main.401/	multimodal	domain	mixed	https://github.com/facebookresearch/simmc2
60	HybriDialogue	\cite{nakamura-etal-2022-hybridialogue}	HybriDialogue: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data	A dialogue dataset, HybriDialogue, which consists of crowdsourced natural conversations grounded on both Wikipedia text and tables. The conversations are created through the decomposition of complex multihop questions into simple, realistic multiturn dialogue interactions.	https://aclanthology.org/2022.findings-acl.41/	multimodal	domain	static	https://github.com/entitize/HybridDialogue
61	KOMODIS	\cite{galetzka-etal-2020-corpus}	A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions for Training Neural Conversation Models	Knowledgable and Opinionated MOvie DIScussions (KOMODIS) is a labeled dialogue dataset in the domain of movie discussions, where every dialogue is based on pre-specified facts and opinions. It contains >7K dialogues and >103K utterances.	https://aclanthology.org/2020.lrec-1.71/	multimodal	domain	static	https://github.com/fabiangal/komodis-dataset
62	SIMMC	\cite{moon-etal-2020-situated}	Situated and Interactive Multimodal Conversations	Situated Interactive MultiModal Conversations (SIMMC) is a dataset with ~13K human-human dialogs (~169K utterances) collected using a multimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture – grounded in a shared virtual environment; and (b) fashion – grounded in an evolving set of images. Data include multimodal context of the items appearing in each scene, and contextual NLU, NLG and coreference annotations.	https://aclanthology.org/2020.coling-main.96/	multimodal	mixed	dynamic	https://github.com/facebookresearch/simmc
63	RED	\cite{welivita-etal-2023-empathetic}	Empathetic Response Generation for Distress Support	Reddit Emotional Distress (RED) is a large-scale dialogue dataset that contains ≈1.3M peer support dialogues spanning across more than 4K distress-related topics.	https://aclanthology.org/2023.sigdial-1.59/	other	contextual	dynamic	https://github.com/yehchunhung/EPIMEED
64	MDMD	\cite{zhang-etal-2022-improving-multi}	Improving Multi-label Malevolence Detection in Dialogues through Multi-faceted Label Correlation Enhancement	 A multi-label dialogue malevolence detection (MDMD) dataset where a dialogue response is considered malevolent if it is grounded in negative emotions, inappropriate behavior, or an unethical value basis in terms of content and dialogue acts. MDMD contains >8K utterances.	https://aclanthology.org/2022.acl-long.248/	other	contextual	dynamic	https://github.com/repozhang/malevolent_dialogue
65	Dynamic OneCommon	\cite{udagawa-aizawa-2021-maintaining}	Maintaining Common Ground in Dynamic Environments	A large-scale dataset of 5617 dialogues to enable fine-grained evaluation, using complex spatio-temporal expressions to create and maintain common ground over time in dynamic environments.	https://aclanthology.org/2021.tacl-1.59/	other	contextual	dynamic	https://github.com/Alab-NII/dynamic-onecommon
66	HuRDL	\cite{gervits-etal-2021-agents}	How Should Agents Ask Questions For Situated Learning? An Annotated Dialogue Corpus	The Human-Robot Dialogue Learning (HuRDL) corpus is a dialogue corpus with 22 dialogues and 1122 turns collected in an online interactive virtual environment in which human participants play the role of a robot performing a collaborative tool-organization task. The data can be used to improve question generation in situated intelligent agents.	https://aclanthology.org/2021.sigdial-1.37/	other	contextual	dynamic	https://github.com/USArmyResearchLab/ARL-HuRDL
67	ESConv	\cite{liu-etal-2021-towards}	Towards Emotional Support Dialog Systems	Emotion Support Conversation dataset (ESConv) with rich annotation (especially support strategy) in a help-seeker and supporter mode for 1K dialogues.	https://aclanthology.org/2021.acl-long.269/	other	contextual	dynamic	https://github.com/thu-coai/Emotional-Support-Conversation
68	CreST	\cite{gervits-etal-2016-disfluent}	Disfluent but effective? A quantitative study of disfluencies and conversational moves in team discourse	A corpus of spontaneous, task-oriented dialogue (CReST corpus), which was annotated for disfluencies and conversational moves that can facilitate grounding and coordination. 	https://aclanthology.org/C16-1317/	other	contextual	dynamic	upon request/unknown
69	EmpatheticDialogues	\cite{rashkin-etal-2019-towards}	Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset	EmpatheticDialogues is a dataset of 25k conversations grounded in emotional situations, the data were gathered from 810 different participants.	https://aclanthology.org/P19-1534/	other	contextual	mixed	https://parl.ai/
70	ProsocialDialog	\cite{kim-etal-2022-prosocialdialog}	ProsocialDialog: A Prosocial Backbone for Conversational Agents	The ProsocialDialog dataset consists of 58K dialogues, with 331K utterances, and 497K dialogue safety labels accompanied by free-form rationales. It can be used for generating more socially acceptable dialogues grounded in social norms.	https://aclanthology.org/2022.emnlp-main.267/	other	domain	static	https://hyunw.kim/prosocial-dialog
71	BSBT	\cite{kim-etal-2022-botstalk}	BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets	Blended Skill BotsTalk (BSBT), a large-scale multi-skill dialogue dataset comprising 300K conversations where agents are grounded to the specific target skills.	https://aclanthology.org/2022.emnlp-main.344/	other	domain	static	https://github.com/convei-lab/BotsTalk
72	JIC	\cite{pal-etal-2025-beyond}	Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations	Journal Intensive Conversations (JIC) is a journal-based conversational dataset with around 400,000 dialogues and a framework for generating personalized conversations using long-form journal entries from Reddit. The data capture common personality traits — openness, conscientiousness, extraversion, agreeableness, and neuroticism — ensuring that dialogues authentically reflect an individual's personality.	https://aclanthology.org/2025.coling-main.470/	persona	contextual	mixed	https://github.com/Sayantan-world/Beyond-Discrete-Personas
73	KBP	\cite{wang-etal-2023-large}	Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues	A personalized knowledge-grounded dialogue dataset Knowledge Behind Persona (KBP) is the first to consider the dependency between persona and implicit knowledge. It comes with >2K dialogues grounded in persona and knowledge.	https://aclanthology.org/2023.findings-emnlp.641/	persona	contextual	static	https://github.com/ruleGreen/SAFARI
74	LiveChat	\cite{gao-etal-2023-livechat}	LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming	The LiveChat dataset is composed of 1.33 million real-life Chinese dialogues with almost 3800 average sessions across 351 personas and fine-grained profiles for each persona representing multi-party conversations.	https://aclanthology.org/2023.acl-long.858/	persona	contextual	static	https://github.com/gaojingsheng/LiveChat
75	PersonaMinEdit	\cite{wu-etal-2021-transferable}	Transferable Persona-Grounded Dialogues via Grounded Minimal Edits	The PersonaMinEdit dataset is derived from PersonaChat with multiple human references for the edited response, it can be used to evaluate persona-grounded minimal editing.	https://aclanthology.org/2021.emnlp-main.183/	persona	contextual	static	https://github.com/thu-coai/grounded-minimal-edit
76	MaLP	\cite{zhang-etal-2024-llm-based}	LLM-based Medical Assistant Personalization with Short- and Long-Term Memory Coordination	The dataset contains 11K dialogues, it is based on an open-source medical corpus and can help with building personalized medical assistants. The dataset is focusing on medical scenarios, including domain and commonsense information as well as personal details (e.g., chronic diseases, dialogue preferences).	https://aclanthology.org/2024.naacl-long.132/	persona	domain	mixed	https://github.com/MatthewKKai/MaLP
77	PeaCoK	\cite{gao-etal-2023-peacok}	PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives	A large-scale persona commonsense knowledge graph, PeaCoK, contains ~100K human-validated persona facts. It formalizes five common aspects of persona knowledge: characteristics, routines and habits, goals and plans, experiences, and relationships.	https://aclanthology.org/2023.acl-long.362/	persona	mixed	static	https://github.com/Silin159/PeaCoK
78	Persona-Chat	\cite{zhang-etal-2018-personalizing}	Personalizing Dialogue Agents: I have a dog, do you have pets too? 	Persona-Chat is a crowd-sourced dataset, collected via Amazon Mechanical Turk, where each of the pair of speakers condition their dialogue on a given profile, which is provided. The dataset is based on 1155 possible personas and provides 11K dialogues.	https://aclanthology.org/P18-1205/	persona	mixed	static	https://github.com/facebookresearch/ParlAI/tree/master/projects/personachat
79	RealPersonaChat	\cite{yamashita-etal-2023-realpersonachat}	RealPersonaChat: A Realistic Persona Chat Corpus with Interlocutors' Own Personalities	RealPersonaChat (RPC) corpus is based on collecting the actual personality traits and personas of interlocutors and having them freely engage in dialogue. This corpus contains 14K dialogues in Japanese and represents one of the largest corpora of dialogue data annotated with personas and personality traits.	https://aclanthology.org/2023.paclic-1.85/	persona	mixed	static	https://github.com/nu-dialogue/real-persona-chat
80	VSTAR	\cite{wang-etal-2023-vstar}	VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions	Video-grounded Scene &Topic AwaRe dialogue (VSTAR) dataset is a large scale video-grounded dialogue understanding dataset based on 395 TV series. It contains annotations for scene and topic transitions. VSTAR contains 185K dialogues.	https://aclanthology.org/2023.acl-long.276/	visual	contextual	dynamic	https://vstar-benchmark.github.io/
81	SIMMC-2.0	\cite{wu-etal-2023-simmc}	SIMMC-VR: A Task-oriented Multimodal Dialog Dataset with Situated and Immersive VR Streams	SIMMC-2.0 is a video-grounded task-oriented dialog dataset that captures real-world AI-assisted user scenarios in virtual reality. It contains fine-grained and scene-grounded annotations for 4K dialogues.	https://aclanthology.org/2023.acl-long.345/	visual	contextual	dynamic	https://github.com/patrick-tssn/VSTAR
82	DVD	\cite{le-etal-2021-dvd}	DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue	A Diagnostic Dataset for Video-grounded Dialogue (DVD) was designed to contain minimal biases and has detailed annotations for the different types of reasoning over the spatio-temporal space of video. Dialogues were synthesized over multiple question turns, each of which was injected with a set of cross-turn semantic relationships. DVD was built from 11k CATER synthetic videos and contains 10 instances of 10-round dialogues for each video, resulting in more than 100k dialogues and 1M question-answer pairs.	https://aclanthology.org/2021.acl-long.439/	visual	contextual	dynamic	https://github.com/facebookresearch/DVDialogues
83	VFD	\cite{kamezawa-etal-2020-visually}	A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses	A visually-grounded first-person dialogue (VFD) dataset with verbal and non-verbal responses. The VFD dataset provides manually annotated (1) first-person images of agents, (2) utterances of human speakers, (3) eye-gaze locations of the speakers, and (4) the agents' verbal and non-verbal responses. For the verbal response selection task, VFD dataset has almost 600K dialogues. For the non-verbal response selection task it contains around 160K dialogues.	https://aclanthology.org/2020.emnlp-main.267/	visual	contextual	dynamic	https://randd.yahoo.co.jp/en/softwaredata
84	PhotoBook	\cite{haber-etal-2019-photobook}	The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue	The dataset was collected through a collaborative game prompting two online participants to refer to images utilising both their visual context as well as previously established referring expressions. This resulted in 2500 annotated dialogues.	https://aclanthology.org/P19-1184/	visual	contextual	dynamic	https://dmg-photobook.github.io/
85	CoDraw	\cite{kim-etal-2019-codraw}	CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication	This dataset is based on a Collaborative image-Drawing game between two agents, called CoDraw. The game is grounded in a virtual world that contains movable clip art objects and involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas using available clip art pieces. The two players communicate with each other using natural language. The CoDraw dataset contains ~10K dialogs with ~138K messages exchanged between human players.	https://aclanthology.org/P19-1651/	visual	contextual	dynamic	https://github.com/facebookresearch/CoDraw
86	CLEVR-Dialog	\cite{kottur-etal-2019-clevr}	CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog	CLEVR-Dialog is a large diagnostic dataset for studying multi-round reasoning in visual dialog. The dialog grammar is grounded in the scene graphs of the images from the CLEVR dataset. This combination results in a dataset where all aspects of the visual dialog are fully annotated. In total, CLEVR-Dialog contains 5 instances of 10-round dialogs for about 85k CLEVR images, totaling to 4.25M question-answer pairs.	https://aclanthology.org/N19-1058/	visual	contextual	dynamic	https://github.com/satwikkottur/clevr-dialog
87	Twitch-FIFA	\cite{pasunuru-bansal-2018-game}	Game-Based Video-Context Dialogue	The Twitch-FIFA dataset is a video-context, many-speaker dialogue dataset based on live-broadcast soccer game videos and chats from Twitch.tv. It is based on 49 FIFA-18 game videos along with their users' chat. The dataset provides the triples with video context, chat context, and response data.	https://aclanthology.org/D18-1012/	visual	contextual	dynamic	https://github.com/ramakanth-pasunuru/video-dialogue
88	GuessWhat?!	\cite{devriesGuesswhatVisualObject2017}	GuessWhat?! Visual object discovery through multi-modal dialogue	The goal of the GuessWhat?! game is to locate an unknown object in a rich image scene by asking a sequence of questions. Higher-level image understanding, like spatial reasoning and language grounding, is required to solve the task. The dataset consists of 150K human-played games with a total of 800K visual question-answer pairs on 66K images.	https://openaccess.thecvf.com/content_cvpr_2017/papers/de_Vries_GuessWhat_Visual_Object_CVPR_2017_paper.pdf	visual	contextual	dynamic	https://guesswhat.ai/download
89	MeetUp!	\cite{ilinykhMeetupCorpusJoint2019}	Meet Up! A Corpus of Joint Activity Dialogues in a Visual Environment	MeetUp! is a two-player coordination game where players move in a visual environment, with the objective of finding each other. To do so, they must talk about what they see, and achieve mutual understanding. The collected data includes 5695 annotated turns.	https://pub.uni-bielefeld.de/download/2955814/2956172/Z19-Ilinykh_semdial_0006.pdf	visual	contextual	dynamic	https://github.com/clp-research/meetup
90	Visually Grounded Follow-up Questions	\cite{dongVisuallyGroundedFollowup2021}	Visually Grounded Follow-up Questions: a Dataset of Spatial Questions Which Require Dialogue History	A dataset of questions that require grounding both on the visual input and the dialogue history. The dataset is based on GuessWhat?! And focuses on the follow-up questions that require multimodal grounding, such questions can be extracted by identifying patterns of trigger-zoomer questions where trigger restricts the context and zoomers are spatial questions that requires triggers to be answered first.	https://aclanthology.org/2021.splurobonlp-1.3/	visual	contextual	dynamic	https://github.com/tianaidong/2021SpLU-RoboNLP-VISPA
91	PentoRef	\cite{zarriessPentorefCorpusSpoken2016}	PentoRef: A Corpus of Spoken References in Task-oriented Dialogues	PentoRef is a corpus of task-oriented dialogues collected in systematically manipulated settings. The corpus is multilingual, with English and German sections, and overall comprises more than 20K utterances. The dialogues are fully transcribed and annotated with referring expressions mapped to objects in corresponding visual scenes, which makes the corpus a rich resource for research on spoken referring expressions in generation and resolution. The corpus includes several sub-corpora that correspond to different dialogue situations where parameters related to interactivity, visual access, and verbal channel have been manipulated in systematic ways.	http://www.lrec-conf.org/proceedings/lrec2016/pdf/563_Paper.pdf	visual	contextual	dynamic	https://github.com/clp-research/pentoref
92	Image-Chat	\cite{shuster-etal-2020-image}	Image-Chat: Engaging Grounded Conversations	Image-Chat consists of 202k dialogues over 202k images using 215 possible style traits. It is a dataset of grounded human-human conversations, where speakers are asked to play roles given a provided emotional mood or style, as the use of such traits is also a key factor in engagingness	https://aclanthology.org/2020.acl-main.219/	visual	contextual	mixed	http://parl.ai/projects/image_chat
93	VisdialConv	\cite{agarwal-etal-2020-history}	History for Visual Dialog: Do we really need it?	VisdialConv is a subset of the VisDial validation set consisting of 97 dialogs, where the crowd-workers identified single turns (with dense annotations) requiring historical information. The crowd-workers were asked whether they could provide an answer to a question given an image, without showing them the dialog history.	https://aclanthology.org/2020.acl-main.728/	visual	contextual	mixed	https://github.com/shubhamagarwal92/visdialconv-amt
94	IGC	\cite{mostafazadeh-etal-2017-image}	Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation	Image Grounded Conversations (IGC) is a dataset in which natural-sounding conversations are generated about a shared image. This is a multiple reference dataset of crowd-sourced, event-centric conversations on images, where visual grounding constrains the topic of conversation. It contains >4K conversations.	https://aclanthology.org/I17-1047/	visual	contextual	mixed	https://www.microsoft.com/en-us/download/details.aspx?id=55324&751be11f-ede8
95	MMChat	\cite{zheng-etal-2022-mmchat}	MMChat: Multi-Modal Chat Dataset on Social Media	MMChat is a large scale Chinese multi-modal dialogue corpus (32.4M raw dialogues and 120.84K filtered dialogues). MMChat contains image-grounded dialogues collected from real conversations on social media.	https://aclanthology.org/2022.lrec-1.621/	visual	contextual	static	https://github.com/silverriver/MMChat
96	Region-under-Discussion for Visual Dialog	\cite{mazuecos-etal-2021-region}	Region under Discussion for visual dialog	A subset of the Guesswhat?! questions for which their dialog history completely changes the responses. Natural language understanding grounded in vision.	https://aclanthology.org/2021.emnlp-main.390/	visual	contextual	static	https://github.com/mmazuecos/Region-under-discussion-for-visual-dialog
97	BURCHAK	\cite{yu-etal-2017-burchak}	The BURCHAK corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings	A human-human dialogue dataset for interactive learning of visually grounded word meanings through ostensive definition by a tutor to a learner. The dataset contains 177 dialogues (each about one visual object) with a total of 2454 turns.	https://aclanthology.org/W17-2001/	visual	mixed	dynamic	https://service.tib.eu/ldmservice/dataset/burchak-corpus
